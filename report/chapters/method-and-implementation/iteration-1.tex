\subsection{Iteration 1: Baseline Setup}
\subsubsection{About}
The initial iteration of this project involved creating a baseline setup based on Antonios Liapis' MiniDungeons project \cite{liapis_minidungeons} ported to Python by ganyariya \cite{GymMd}.
This iteration was used to provide a testbed for evalutating the quality of levels generated by the future level generator. MiniDungeons was used as a testbed as a means of
limiting the scope of the project to generating levels, rather than creating a full game \textit{and} levels.

The Python port of MiniDungeons (\texttt{gym-md}) \cite{GymMd} proved to be a sufficient starting point for this projects goals, however it was created using a legacy version of Gymnasium \cite{Gymnasium}\cite{towers2025gymnasiumstandardinterfacereinforcement}.
For that reason, in order to avoid issues with dependencies, a fork of \texttt{gym-md}\cite{GymMdFork} was created with the express purpose of updating its core dependencies to allow further development.

The final step of this iteration was to setup the project repository to be able to run and modify MiniDungeons from a central location. The project was created using Poetry\cite{PythonPoetry} to manage dependencies and standardize entry points for the code.
The project was setup to extend \texttt{gym-md} while still allowing for new levels to be used in the environment. The iteration concluded with a standard entry point for running
MiniDungeons with hardcoded custom dungeon layouts.

\subsubsection{Evaluation}
As this iteration focused on the technical infrastructure and software architecture rather than a playable artifact, the evaluation consisted of technical verification and functional integration testing rather than user studies.

\textbf{Verification Objectives:} The primary objective was to verify that the updated Gymnasium environment could successfully read and render custom level data, to serve as a reliable testbed for the PCG algorithms to be developed in future iterations.
Specifically, the system needed to pass three criteria:
\begin{enumerate}
	\item \textbf{Dependency Stability:} The project must install deterministically via Poetry without conflict between the legacy gym-md logic and modern Python 3.13 standards.
	\item \textbf{Execution:} The environment must run a simulation loop with agent movement and interactions, which is necessary for testing batch-generated levels.
	\item \textbf{Map Injection:} The system must accept a custom 2D character array (representing a dungeon level) at runtime and correctly initialize the game state based on that array.
\end{enumerate}

\textbf{Testing Methodology:} \texttt{gym-md} came pre-configured with a suite of tests that was used for verifying the updated \texttt{gym-md} fork.
A "Random Agent" baseline was implemented to send random action inputs to the environment for 1000 steps to ensure no runtime errors occurred during state transitions.
To test custom map injections, a hardcoded level containing all possible game elements (walls, monsters, potions, exit) was passed to the environment constructor.

\textbf{Results:} The fork of \texttt{gym-md} successfully executed the simulation loop using the updated Gymnasium API.
The Poetry configuration resolved the dependency graph, eliminating the version conflicts that would have otherwise been present in the development repository.
Most importantly, the map injection test confirmed that the environment could dynamically load layouts provided by an external source. However, in order to run these injected levels it was necessary 
to also create various standalone configuration files alongside each level and therefore this test was only considered partially successful.

\subsubsection{Reflections and decisions}
The results of the technical evaluation confirmed that the baseline setup was stable and ready for procedural content generation integration, however not without some complications regarding iteration speed.

\textbf{Interpretation:} The successful map injection was the most critical outcome of this iteration.
It confirmed that the MiniDungeons environment could be decoupled from the pre-defined level data from within the \texttt{gym-md} package. Running injected levels also required creating various configuration files to manage internal settings of the environment. 
Due to the subject of this project being about procedural content generation, modifying internal settings for each level was deemed outside the scope of the research questions and therefore meant unnecessary overhead for the project.
While this iteration validated the decision to use this specific framework, it was clear that some further modification was needed.

\textbf{Impact on Future Iterations:} Although the baseline structure showed success, the cumbersome nature of creating the required artifacts for the MiniDungeon environment 
lead the next iteration to focus on simplifying the environments loading requirements. In iteration 2, the goal would be to reduce the required artifacts to just the 2D character array representing the level, rather than also creating extra artifacts.
Additonally, the implemented random agent does not provide a sufficient baseline for validating the quality of a generated level, as the data would be fully inconsistent and separeted from the actual level content. Iteration 2 also needed to address this issue before a generator could be created. 